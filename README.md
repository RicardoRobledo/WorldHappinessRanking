# ğŸŒ Project: World Happiness Report Analysis and Prediction

## ğŸ“‹ Project Description
Exploratory analysis and predictive modeling of the World Happiness Report using 2015 data, with the goal of predicting countries' happiness scores based on economic and social factors.

---

## ğŸ”„ Steps Performed

### 1ï¸âƒ£ Data Loading and Exploration
- ğŸ“¥ Downloaded dataset from Kaggle (World Happiness Ranking Dataset)
- ğŸ“Š Loaded 1,231 records with 14 columns
- ğŸ” Identified significant null values in multiple columns

### 2ï¸âƒ£ Exploratory Analysis
- ğŸ“ˆ Visualized missing values using `missingno`
- ğŸ”¥ Generated correlation matrix to identify relationships between variables
- â­ Notable correlation: Happiness Score and Family (0.694)

### 3ï¸âƒ£ Data Cleaning
- ğŸ§¹ Removed records without Happiness Score
- âŒ Dropped columns with high missing data or irrelevant features:
  - Unnamed: 0
  - Region
  - Happiness Rank
  - Standard Error
  - Family
  - Health (Life Expectancy)
  - Trust (Government Corruption)
  - Dystopia Residual
- ğŸ¯ Filtered data for year 2015
- âœ… Final dataset: 158 records

### 4ï¸âƒ£ Final Variables Used
**ğŸ¯ Target Variable:**
- Happiness Score

**ğŸ“Š Predictor Variables:**
- Economy (GDP per Capita)
- Freedom
- Generosity
- Country

### 5ï¸âƒ£ Data Preparation
- ğŸ“‚ Dataset split:
  - 60% training
  - 20% validation
  - 20% testing
- âš™ï¸ Preprocessing pipeline:
  - Missing value imputation (SimpleImputer with 'mean' strategy for numerical)
  - Robust scaling (RobustScaler)
  - One-hot encoding for categorical variables

### 6ï¸âƒ£ Model Evaluation
Tested 13 regression models using cross-validation (RepeatedKFold, 3 splits, 3 repeats):

| Model | Mean MAE | Std. Dev. |
|--------|----------|-----------|
| Linear Regression | 0.500 | 0.050 |
| Random Forest | 0.478 | 0.050 |
| Extra Trees | 0.478 | 0.058 |
| AdaBoost | 0.503 | 0.045 |
| Gradient Boosting | 0.505 | 0.043 |
| Theil-Sen | 0.508 | 0.058 |
| SGD Regressor | 0.516 | 0.064 |
| Poisson | 0.526 | 0.055 |
| KNN | 0.534 | 0.059 |
| SVR | 0.547 | 0.053 |
| Decision Tree | 0.579 | 0.056 |
| Tweedie | 0.701 | 0.081 |
| Quantile | 0.954 | 0.110 |

### 7ï¸âƒ£ Selected Model
**ğŸ† Linear Regression** was chosen for:
- âœ… Good balance between accuracy and simplicity
- ğŸ“Š Greater stability across validations
- ğŸ’¡ Better interpretability
- ğŸ¯ Consistent results

### 8ï¸âƒ£ Final Model Evaluation

**ğŸ“ˆ Validation Metrics:**
- MAE: 0.500
- MSE: 0.350
- RMSE: 0.592
- RÂ²: 0.730

**ğŸ¯ Test Metrics:**
- MAE: 0.490
- MSE: 0.340
- RMSE: 0.583
- RÂ²: 0.740

---

## ğŸ¯ Results

The Linear Regression model successfully explained approximately **74% of the variance** in happiness scores (RÂ² = 0.74), with an average error of **0.49 points** on the happiness scale.

---

## ğŸ’¡ Key Findings

1. **ğŸ”— Significant correlation:** The "Family" factor showed a 0.694 correlation with Happiness Score, being one of the most relevant predictors before its removal.

2. **âš–ï¸ Model stability:** Linear Regression proved more robust than more complex models like Random Forest or Extra Trees, despite these showing slightly lower MAE values.

3. **ğŸ”„ Imputation order irrelevant:** Different imputation orders (roman, arabic, ascending, descending) were tested with IterativeImputer, all producing identical results, confirming that order doesn't affect performance on this dataset.

4. **âš¡ Effective simplicity:** More complex models didn't offer significant improvements to justify their greater computational complexity.

5. **ğŸ’° Economic and social predictors:** The variables Economy (GDP per Capita), Freedom, and Generosity were sufficient to obtain reasonable predictions of happiness levels.

---

## ğŸ“ Conclusions

âœ… Linear Regression is an effective solution for predicting Happiness Score, balancing accuracy, interpretability, and simplicity.

âœ… With only three numerical variables (Economy, Freedom, Generosity), it's possible to reasonably predict a country's happiness level.

âœ… The average error of ~0.5 points is acceptable considering the scale ranges from 0 to 10 and the observed range was 2.8 to 7.6.

âš ï¸ The high amount of missing data in the original dataset (especially in recent years) limited the analysis to 2015 data.

ğŸš€ To improve the model, it would be beneficial to obtain more complete and recent data, as well as explore interactions between variables.
